{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mark-wijnands/internship_rainbow_mwijnands/blob/main/CollisionNetwork_2layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z74GfaZL71mm"
      },
      "source": [
        "# Notebook to train and evaluate a collision detection network developed by M. Wijnands for the Rainbow institute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG-urc8g8PKO"
      },
      "source": [
        "Install and import packages. Torchmetrics is not a standard colab package and has to be installed using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF9h1ni4DkHm",
        "outputId": "797c7b18-4c07-4ccb-da60-378b375a0205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchmetrics\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iuh2Kmo8b4s"
      },
      "source": [
        "Mount drive for extracting the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqmE7b7sDk11",
        "outputId": "52c254b5-1baf-4982-b844-994870a9273a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlx7voA38gHy"
      },
      "source": [
        "Create test and train dataset classes and initialize:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h97hcPgzDk-6"
      },
      "outputs": [],
      "source": [
        "class CollisionDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, path, convertion) -> None:\n",
        "      self.path = path\n",
        "      self.convertion = convertion\n",
        "      with open(path+'Xnorm') as f1:\n",
        "          lines = f1.readlines()\n",
        "          self.source = [line.split() for line in lines]\n",
        "      with open(path+'labels') as f1:\n",
        "          lines = f1.readlines()\n",
        "          self.target = [line.split() for line in lines]\n",
        "\n",
        "  def convert(self,x,convertion):\n",
        "    if convertion == 0:\n",
        "      pass\n",
        "    if convertion == 1:\n",
        "      if x > 0:\n",
        "        x = 1\n",
        "    if convertion == 2:\n",
        "      if x == 1:\n",
        "        x = 0\n",
        "      else:\n",
        "        x = 1\n",
        "    if convertion == 3:\n",
        "      if x == 2:\n",
        "        x = 0\n",
        "      else:\n",
        "        x = 1\n",
        "    return x\n",
        "\n",
        "  def __getitem__(self, idx) -> torch.Tensor:\n",
        "      source_sample = self.source[idx]\n",
        "      target_sample = self.target[idx]\n",
        "\n",
        "      source_sample = [float(x) for x in source_sample]\n",
        "      \n",
        "      # #augment:\n",
        "      # W = int(len(source_sample)/7)\n",
        "      # for i in range(7):\n",
        "      #   multiplier = 0.5+random.randrange(0, 1000, 1)/1000\n",
        "      #   for j in range(W):\n",
        "      #     source_sample[i+7*j] = multiplier*source_sample[i+7*j]\n",
        "\n",
        "      source_sample = np.array(source_sample, dtype=np.float16)\n",
        "\n",
        "      target_sample = [float(x) for x in target_sample]\n",
        "      target_sample = [int(x) for x in target_sample]\n",
        "      target_sample = [self.convert(x,self.convertion) for x in target_sample]\n",
        "      target_sample = np.array(target_sample)\n",
        "\n",
        "      source_sample = torch.tensor(source_sample, dtype=torch.double)\n",
        "      target_sample = torch.tensor(target_sample, dtype=torch.int32)\n",
        "\n",
        "      source_sample = source_sample[None, :]\n",
        "      target_sample = target_sample[None, :]\n",
        "\n",
        "      return source_sample, target_sample\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.target)\n",
        "\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(42)        #in order to keep same sets as trained on (otherwise samples in eval that were trained on) --> obsolete because of earlier split in train/test v.s. eval\n",
        "\n",
        "dataset1 =  CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/ds7_avg2_W10/set1/',1)\n",
        "dataset2 =  CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/ds7_avg2_W10/set2/',2)\n",
        "dataset3 =  CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/ds7_avg2_W10/set3/',3)\n",
        "\n",
        "trainlen1 = int(0.8*dataset1.__len__())\n",
        "testlen1 = dataset1.__len__() - trainlen1\n",
        "testdataset1, traindataset1 = torch.utils.data.random_split(dataset1, [testlen1, trainlen1], generator=generator)\n",
        "\n",
        "trainlen2 = int(0.8*dataset2.__len__())\n",
        "testlen2 = dataset2.__len__() - trainlen2\n",
        "testdataset2, traindataset2 = torch.utils.data.random_split(dataset2, [testlen2, trainlen2], generator=generator)\n",
        "\n",
        "trainlen3 = int(0.8*dataset3.__len__())\n",
        "testlen3 = dataset3.__len__() - trainlen3\n",
        "testdataset3, traindataset3 = torch.utils.data.random_split(dataset3, [testlen3, trainlen3], generator=generator)\n",
        "\n",
        "evalset = CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/ds7_test_avg2_eval_W30/',0)\n",
        "\n",
        "save_path1 = \"/content/drive/MyDrive/Colab Notebooks/Models_ds7_2layer_ch64_ch128_W10_avg2/ModelsNN1\"\n",
        "save_path2 = \"/content/drive/MyDrive/Colab Notebooks/Models_ds7_2layer_ch64_ch128_W10_avg2/ModelsNN2\"\n",
        "save_path3 = \"/content/drive/MyDrive/Colab Notebooks/Models_ds7_2layer_ch64_ch128_W10_avg2/ModelsNN3\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCqAbU3B8lh2"
      },
      "source": [
        "Create network class. Normal 1D convolutions with alternating valid and same padding are used. There is no sigmoid as the out function, as a BCEWithLogitsLoss is used in the training which already incorporates this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAckOqmF5lsb"
      },
      "outputs": [],
      "source": [
        "class CollisionNetwork(nn.Module):\n",
        "\n",
        "\tdef __init__(self, no_layers=11, kernel = 3, device=None):\n",
        "\t\tsuper(CollisionNetwork, self).__init__()\n",
        "\t\tself.no_layers = no_layers\n",
        "\t\tself.kernel = kernel\n",
        "\t\tself.layers = {}\n",
        "\t\tself.device = device\n",
        "\n",
        "\t\tself.Conv1d_1 = nn.Conv1d(1, 64, kernel, stride=1, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\tself.BatchNorm1d_1 = nn.BatchNorm1d(64, dtype=torch.double)\n",
        "\t\tself.ReLU_1= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv1d_2 = nn.Conv1d(64, 128, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\tself.BatchNorm1d_2 = nn.BatchNorm1d(128, dtype=torch.double)\n",
        "\t\tself.ReLU_2= nn.ReLU(True)        \n",
        "\n",
        "\t\t# self.Conv1d_3 = nn.Conv1d(32, 32, kernel, stride=1, dilation=2, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_3 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_3= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_4 = nn.Conv1d(32, 64, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_4 = nn.BatchNorm1d(64, dtype=torch.double)\n",
        "\t\t# self.ReLU_4= nn.ReLU(True)    \n",
        "\t\n",
        "\t\t# self.Conv1d_5 = nn.Conv1d(64, 64, kernel, stride=1, dilation=4, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_5 = nn.BatchNorm1d(64, dtype=torch.double)\n",
        "\t\t# self.ReLU_5= nn.ReLU(True)        \n",
        "\n",
        "\t\t# self.Conv1d_6 = nn.Conv1d(64, 64, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_6 = nn.BatchNorm1d(64, dtype=torch.double)\n",
        "\t\t# self.ReLU_6= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_7 = nn.Conv1d(64, 128, kernel, stride=1, dilation=8, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_7 = nn.BatchNorm1d(128, dtype=torch.double)\n",
        "\t\t# self.ReLU_7= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_8 = nn.Conv1d(128, 128, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_8 = nn.BatchNorm1d(128, dtype=torch.double)\n",
        "\t\t# self.ReLU_8= nn.ReLU(True) \n",
        "\n",
        "\t\tself.Flatten = nn.Flatten()\n",
        "\t\n",
        "\t\tself.out = nn.Linear(8704,1, dtype=torch.double) \n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.Conv1d_1(x)\n",
        "\t\tx = self.BatchNorm1d_1(x)\n",
        "\t\tx = self.ReLU_1(x)\n",
        "\n",
        "\t\tx = self.Conv1d_2(x)\n",
        "\t\tx = self.BatchNorm1d_2(x)\n",
        "\t\tx = self.ReLU_2(x)\n",
        "\n",
        "\t\t# x = self.Conv1d_3(x)\n",
        "\t\t# x = self.BatchNorm1d_3(x)\n",
        "\t\t# x = self.ReLU_3(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_4(x)\n",
        "\t\t# x = self.BatchNorm1d_4(x)\n",
        "\t\t# x = self.ReLU_4(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_5(x)\n",
        "\t\t# x = self.BatchNorm1d_5(x)\n",
        "\t\t# x = self.ReLU_5(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_6(x)\n",
        "\t\t# x = self.BatchNorm1d_6(x)\n",
        "\t\t# x = self.ReLU_6(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_7(x)\n",
        "\t\t# x = self.BatchNorm1d_7(x)\n",
        "\t\t# x = self.ReLU_7(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_8(x)\n",
        "\t\t# x = self.BatchNorm1d_8(x)\n",
        "\t\t# x = self.ReLU_8(x)\n",
        "\t\n",
        "\t\tx = self.Flatten(x)\n",
        "  \n",
        "\t\treturn self.out(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwhs2C6B8578"
      },
      "source": [
        "Train the network. Batch size and epochs can be chosen here. A weight is given in the BCE criterion as there are far more non-collision samples. Otherwise accuracy will be high, recall will be bad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "xkzlwKfGJzOD",
        "outputId": "63b23fc8-d286-4e93-dbc8-4e5ccbac9c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Started\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-b86f817030b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-11459216044e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x8704 and 26624x1)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "# save_path = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30/ModelsNN1\"\n",
        "save_path = save_path1\n",
        "\n",
        "train = DataLoader(traindataset1, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "test = DataLoader(testdataset1, batch_size=batch_size, shuffle=False, num_workers =1, pin_memory = True)\n",
        "\n",
        "#Defining the model and training it on loss function\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = CollisionNetwork().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "pos_weight = torch.ones([1])\t\t\t\t\t\t\t\t\t#-- there is about 20-25x more no_collision data so add pos_weight to balance\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) \t\t\t#more weight for false_positives, as dataset contains far more negative collision samples\n",
        "\n",
        "loss_overall = []\n",
        "acc_overall = [None]*epochs\n",
        "recall_overall = [None]*epochs\n",
        "precision_overall = [None]*epochs\n",
        "acc_overall_test = [None]*epochs\n",
        "acc_overall_train = [None]*epochs\n",
        "time_start = time.time()\n",
        "print('Training Started')\n",
        "\n",
        "train_accuracy = torchmetrics.Accuracy() \t\t\t#in order to check if model learns properly\n",
        "# train_recall = torchmetrics.Recall()\n",
        "# train_precision =  torchmetrics.Precision()\n",
        "\n",
        "plt.figure()\n",
        "for i in range(epochs):\n",
        "\n",
        "  net.train(True)\n",
        "  step = 0\n",
        "  loss_= 0\n",
        "  for images, target in train:\n",
        "\n",
        "    target = target.squeeze()\n",
        "    target = target.double()\n",
        "    images = images.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = net(images)\n",
        "    output = output.squeeze()\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    out_rounded = torch.round(output)\n",
        "    target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "    acc = train_accuracy(out_rounded, target_tensor)\n",
        "\n",
        "    # recall = train_recall(out_rounded, target_tensor)\n",
        "    # recall_overall[i] = recall.item()\n",
        "\n",
        "    # precision = train_precision(out_rounded, target_tensor)\n",
        "    # precision_overall[i] = precision.item()\n",
        "\n",
        "    loss_+=loss\n",
        "    step+=1\n",
        "\n",
        "    # if(step%100 == 0):\n",
        "    #   print('Epoch:'+str(i)+'\\t'+ str(step) +'\\t Iterations Complete \\t'+'loss: ', loss.item()/1000.0)\n",
        "    #   loss_overall.append(loss_/1000.0)\n",
        "    #   loss_=0\n",
        "\n",
        "  total_train_accuracy = train_accuracy.compute()\n",
        "  print(f\"Accuracy: {total_train_accuracy}\")\n",
        "  train_accuracy.reset()\n",
        "  # total_train_recall= train_recall.compute()\n",
        "  # print(f\"Recall: {total_train_recall}\")\n",
        "  # train_recall.reset()    \n",
        "  # total_train_precision = train_precision.compute()\n",
        "  # print(f\"Precision: {total_train_precision}\")\n",
        "  # train_precision.reset()\n",
        "\n",
        "  #Saving the model\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "  if(i==epochs-1):\n",
        "    torch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+'Last'+'.pt')\n",
        "  else:\n",
        "    torch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+str(i)+'.pt')\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  test_accuracy = torchmetrics.Accuracy() \n",
        "  test_confusion = torchmetrics.ConfusionMatrix(num_classes=2)\n",
        "  for sample, target in test:\n",
        "      target = target.squeeze()\n",
        "      target = target.double()\n",
        "      sample = sample.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      out = net(sample).squeeze()\n",
        "\n",
        "      out_rounded = torch.round(out)\n",
        "      target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "      acc = test_accuracy(out_rounded, target_tensor)\n",
        "\n",
        "      confusion = test_confusion(out_rounded, target_tensor)\n",
        "\n",
        "  total_test_accuracy = test_accuracy.compute()\n",
        "  print(f\"Accuracy: {total_test_accuracy}\")\n",
        "  test_accuracy.reset()\n",
        "  total_test_confusion = test_confusion.compute()\n",
        "  print(f\"Confusion: {total_test_confusion}\")\n",
        "  test_confusion.reset()\n",
        "\n",
        "print('Training Finished! Time Taken: ', time.time()-time_start)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJUg0VKT9TY1"
      },
      "source": [
        "Load the model from the last checkpoint and evaluate. Note that W should equal the window size W of the used data and batch_size of the test and train loaders should be equal!! (variable has been declared here again s.t. the cell can be run independent of the training cell)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H4WOXKmJa87"
      },
      "source": [
        "# Second network: hard v.s. soft classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpkd6aloJvIb"
      },
      "outputs": [],
      "source": [
        "class CollisionNetwork2(nn.Module):\n",
        "\n",
        "\tdef __init__(self, no_layers=11, kernel = 3, device=None):\n",
        "\t\tsuper(CollisionNetwork2, self).__init__()\n",
        "\t\tself.no_layers = no_layers\n",
        "\t\tself.kernel = kernel\n",
        "\t\tself.layers = {}\n",
        "\t\tself.device = device\n",
        "\n",
        "\t\tself.Conv1d_1 = nn.Conv1d(1, 64, kernel, stride=1, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\tself.BatchNorm1d_1 = nn.BatchNorm1d(64, dtype=torch.double)\n",
        "\t\tself.ReLU_1= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv1d_2 = nn.Conv1d(64, 128, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\tself.BatchNorm1d_2 = nn.BatchNorm1d(128, dtype=torch.double)\n",
        "\t\tself.ReLU_2= nn.ReLU(True)        \n",
        "\n",
        "\t\t# self.Conv1d_3 = nn.Conv1d(32, 32, kernel, stride=1, dilation=2, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_3 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_3= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_4 = nn.Conv1d(32, 32, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_4 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_4= nn.ReLU(True)    \n",
        "\t\n",
        "\t\t# self.Conv1d_5 = nn.Conv1d(32, 32, kernel, stride=1, dilation=4, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_5 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_5= nn.ReLU(True)        \n",
        "\n",
        "\t\t# self.Conv1d_6 = nn.Conv1d(32, 32, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_6 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_6= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_7 = nn.Conv1d(32, 32, kernel, stride=1, dilation=8, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_7 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_7= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_8 = nn.Conv1d(32, 32, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_8 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_8= nn.ReLU(True) \n",
        "\n",
        "\t\tself.Flatten = nn.Flatten()\n",
        "\t\n",
        "\t\tself.out = nn.Linear(8704,1, dtype=torch.double) \n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.Conv1d_1(x)\n",
        "\t\tx = self.BatchNorm1d_1(x)\n",
        "\t\tx = self.ReLU_1(x)\n",
        "\n",
        "\t\tx = self.Conv1d_2(x)\n",
        "\t\tx = self.BatchNorm1d_2(x)\n",
        "\t\tx = self.ReLU_2(x)\n",
        "\n",
        "\t\t# x = self.Conv1d_3(x)\n",
        "\t\t# x = self.BatchNorm1d_3(x)\n",
        "\t\t# x = self.ReLU_3(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_4(x)\n",
        "\t\t# x = self.BatchNorm1d_4(x)\n",
        "\t\t# x = self.ReLU_4(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_5(x)\n",
        "\t\t# x = self.BatchNorm1d_5(x)\n",
        "\t\t# x = self.ReLU_5(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_6(x)\n",
        "\t\t# x = self.BatchNorm1d_6(x)\n",
        "\t\t# x = self.ReLU_6(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_7(x)\n",
        "\t\t# x = self.BatchNorm1d_7(x)\n",
        "\t\t# x = self.ReLU_7(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_8(x)\n",
        "\t\t# x = self.BatchNorm1d_8(x)\n",
        "\t\t# x = self.ReLU_8(x)\n",
        "\t\n",
        "\t\tx = self.Flatten(x)\n",
        "  \n",
        "\t\treturn self.out(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_hAKc6iJvOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78b3e70c-31fe-42fb-b8bc-be2fd6b1ed18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6620667576789856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75738126039505\n",
            "Confusion: tensor([[387, 174],\n",
            "        [204, 793]])\n",
            "Accuracy: 0.6901476383209229\n",
            "Accuracy: 0.7310654520988464\n",
            "Confusion: tensor([[503,  58],\n",
            "        [361, 636]])\n",
            "Accuracy: 0.7174261808395386\n",
            "Accuracy: 0.7079589366912842\n",
            "Confusion: tensor([[524,  37],\n",
            "        [418, 579]])\n",
            "Accuracy: 0.7310654520988464\n",
            "Accuracy: 0.7541720271110535\n",
            "Confusion: tensor([[440, 121],\n",
            "        [262, 735]])\n",
            "Accuracy: 0.7297817468643188\n",
            "Accuracy: 0.7920410633087158\n",
            "Confusion: tensor([[499,  62],\n",
            "        [262, 735]])\n",
            "Accuracy: 0.7262516021728516\n",
            "Accuracy: 0.7188703417778015\n",
            "Confusion: tensor([[525,  36],\n",
            "        [402, 595]])\n",
            "Accuracy: 0.7408536672592163\n",
            "Accuracy: 0.7637997269630432\n",
            "Confusion: tensor([[371, 190],\n",
            "        [178, 819]])\n",
            "Accuracy: 0.7421373724937439\n",
            "Accuracy: 0.7650834321975708\n",
            "Confusion: tensor([[529,  32],\n",
            "        [334, 663]])\n",
            "Accuracy: 0.7496790885925293\n",
            "Accuracy: 0.7567394375801086\n",
            "Confusion: tensor([[524,  37],\n",
            "        [342, 655]])\n",
            "Accuracy: 0.7641206383705139\n",
            "Accuracy: 0.7682926654815674\n",
            "Confusion: tensor([[468,  93],\n",
            "        [268, 729]])\n",
            "Accuracy: 0.7679717540740967\n",
            "Accuracy: 0.7528883218765259\n",
            "Confusion: tensor([[545,  16],\n",
            "        [369, 628]])\n",
            "Accuracy: 0.7652438879013062\n",
            "Accuracy: 0.8003851175308228\n",
            "Confusion: tensor([[463,  98],\n",
            "        [213, 784]])\n",
            "Accuracy: 0.7718228697776794\n",
            "Accuracy: 0.8080872893333435\n",
            "Confusion: tensor([[456, 105],\n",
            "        [194, 803]])\n",
            "Accuracy: 0.7875481247901917\n",
            "Accuracy: 0.8260590434074402\n",
            "Confusion: tensor([[480,  81],\n",
            "        [190, 807]])\n",
            "Accuracy: 0.7828947305679321\n",
            "Accuracy: 0.8119384050369263\n",
            "Confusion: tensor([[487,  74],\n",
            "        [219, 778]])\n",
            "Accuracy: 0.7848202586174011\n",
            "Accuracy: 0.7618741989135742\n",
            "Confusion: tensor([[539,  22],\n",
            "        [349, 648]])\n",
            "Accuracy: 0.7938061356544495\n",
            "Accuracy: 0.7560975551605225\n",
            "Confusion: tensor([[541,  20],\n",
            "        [360, 637]])\n",
            "Accuracy: 0.7861039638519287\n",
            "Accuracy: 0.7811296582221985\n",
            "Confusion: tensor([[519,  42],\n",
            "        [299, 698]])\n",
            "Accuracy: 0.7902759909629822\n",
            "Accuracy: 0.8119384050369263\n",
            "Confusion: tensor([[519,  42],\n",
            "        [251, 746]])\n",
            "Accuracy: 0.8093709945678711\n",
            "Accuracy: 0.8254172205924988\n",
            "Confusion: tensor([[499,  62],\n",
            "        [210, 787]])\n",
            "Accuracy: 0.8104942440986633\n",
            "Accuracy: 0.8080872893333435\n",
            "Confusion: tensor([[502,  59],\n",
            "        [240, 757]])\n",
            "Accuracy: 0.8047176003456116\n",
            "Accuracy: 0.7881900072097778\n",
            "Confusion: tensor([[521,  40],\n",
            "        [290, 707]])\n",
            "Accuracy: 0.8180359601974487\n",
            "Accuracy: 0.8395378589630127\n",
            "Confusion: tensor([[499,  62],\n",
            "        [188, 809]])\n",
            "Accuracy: 0.8119384050369263\n",
            "Accuracy: 0.819640576839447\n",
            "Confusion: tensor([[526,  35],\n",
            "        [246, 751]])\n",
            "Accuracy: 0.817715048789978\n",
            "Accuracy: 0.7939666509628296\n",
            "Confusion: tensor([[505,  56],\n",
            "        [265, 732]])\n",
            "Accuracy: 0.8209242820739746\n",
            "Accuracy: 0.8273427486419678\n",
            "Confusion: tensor([[518,  43],\n",
            "        [226, 771]])\n",
            "Accuracy: 0.8236520886421204\n",
            "Accuracy: 0.8523748517036438\n",
            "Confusion: tensor([[485,  76],\n",
            "        [154, 843]])\n",
            "Accuracy: 0.8273427486419678\n",
            "Accuracy: 0.8543003797531128\n",
            "Confusion: tensor([[483,  78],\n",
            "        [149, 848]])\n",
            "Accuracy: 0.8223684430122375\n",
            "Accuracy: 0.829910159111023\n",
            "Confusion: tensor([[484,  77],\n",
            "        [188, 809]])\n",
            "Accuracy: 0.8326380252838135\n",
            "Accuracy: 0.8388960361480713\n",
            "Confusion: tensor([[498,  63],\n",
            "        [188, 809]])\n",
            "Training Finished! Time Taken:  479.11868834495544\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "# save_path = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30/ModelsNN2\"\n",
        "save_path = save_path2\n",
        "\n",
        "# train = DataLoader(traindataset2, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "# test = DataLoader(testdataset2, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "\n",
        "train = DataLoader(traindataset2, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "test = DataLoader(testdataset2, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "\n",
        "#Defining the model and training it on loss function\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = CollisionNetwork2().to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(net.parameters())\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=0.0004, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "pos_weight = torch.ones([1])\t\t\t\t\t        #-- there is about 6x more soft_collision data so add pos_weight to balance --> obsolete because of new balanced sampler\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) \t\t\t#more weight for false_positives, as dataset contains far more negative collision samples\n",
        "# criterion = nn.BCEWithLogitsLoss() \t\t\t#more weight for false_positives, as dataset contains far more negative collision samples\n",
        "\n",
        "loss_overall = []\n",
        "acc_overall = [None]*epochs\n",
        "recall_overall = [None]*epochs\n",
        "precision_overall = [None]*epochs\n",
        "acc_overall_test = [None]*epochs\n",
        "acc_overall_train = [None]*epochs\n",
        "time_start = time.time()\n",
        "print('Training Started')\n",
        "\n",
        "train_accuracy = torchmetrics.Accuracy() \t\t\t#in order to check if model learns properly\n",
        "# train_recall = torchmetrics.Recall()\n",
        "# train_precision =  torchmetrics.Precision()\n",
        "\n",
        "plt.figure()\n",
        "for i in range(epochs):\n",
        "\n",
        "  net.train(True)\n",
        "  step = 0\n",
        "  loss_= 0\n",
        "  for images, target in train:\n",
        "\n",
        "    # images, target = next(iter(train))\n",
        "    target = target.squeeze()\n",
        "    target = target.double()\n",
        "    images = images.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = net(images)\n",
        "    output = output.squeeze()\n",
        "\n",
        "    # print(np.shape(output))\n",
        "    # print(np.shape(target))\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    out_rounded = torch.round(output)\n",
        "    target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "    acc = train_accuracy(out_rounded, target_tensor)\n",
        "    acc_overall_test[i] = acc.item()\n",
        "\n",
        "    # recall = train_recall(out_rounded, target_tensor)\n",
        "    # recall_overall[i] = recall.item()\n",
        "\n",
        "    # precision = train_precision(out_rounded, target_tensor)\n",
        "    # precision_overall[i] = precision.item()\n",
        "\n",
        "    loss_+=loss\n",
        "    step+=1\n",
        "\n",
        "    # if(step%100 == 0):\n",
        "    #   print('Epoch:'+str(i)+'\\t'+ str(step) +'\\t Iterations Complete \\t'+'loss: ', loss.item()/1000.0)\n",
        "    #   loss_overall.append(loss_/1000.0)\n",
        "    #   loss_=0\n",
        "\n",
        "  total_train_accuracy = train_accuracy.compute()\n",
        "  print(f\"Accuracy: {total_train_accuracy}\")\n",
        "  train_accuracy.reset()\n",
        "  # total_train_recall= train_recall.compute()\n",
        "  # print(f\"Recall: {total_train_recall}\")\n",
        "  # train_recall.reset()    \n",
        "  # total_train_precision = train_precision.compute()\n",
        "  # print(f\"Precision: {total_train_precision}\")\n",
        "  # train_precision.reset()\n",
        "\n",
        "  #Saving the model\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "  if(i==epochs-1):\n",
        "    torch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+'Last'+'.pt')\n",
        "  else:\n",
        "    torch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+str(i)+'.pt')\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  test_accuracy = torchmetrics.Accuracy() \n",
        "  test_confusion = torchmetrics.ConfusionMatrix(num_classes=2)\n",
        "  for sample, target in test:\n",
        "      target = target.squeeze()\n",
        "      target = target.double()\n",
        "      sample = sample.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      out = net(sample).squeeze()\n",
        "\n",
        "      out_rounded = torch.round(out)\n",
        "      target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "      acc = test_accuracy(out_rounded, target_tensor)\n",
        "      acc_overall_test[i] = acc.item()\n",
        "\n",
        "      confusion = test_confusion(out_rounded, target_tensor)\n",
        "\n",
        "  total_test_accuracy = test_accuracy.compute()\n",
        "  print(f\"Accuracy: {total_test_accuracy}\")\n",
        "  test_accuracy.reset()\n",
        "  total_test_confusion = test_confusion.compute()\n",
        "  print(f\"Confusion: {total_test_confusion}\")\n",
        "  test_confusion.reset()\n",
        "\n",
        "print('Training Finished! Time Taken: ', time.time()-time_start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0hi3oxPKMYg"
      },
      "outputs": [],
      "source": [
        "# plt.figure()\n",
        "# plt.plot(acc_overall, label='accuracy')\n",
        "# plt.plot(recall_overall, label='recall')\n",
        "# plt.plot(precision_overall, label='precision')\n",
        "# plt.title('Training metrics')\n",
        "# plt.xlabel('epochs')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(loss_overall)\n",
        "# plt.show()\n",
        "\n",
        "# # print(acc_overall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wK_2NY_KMbE"
      },
      "outputs": [],
      "source": [
        "# # load_path = \"/content/drive/MyDrive/Colab Notebooks/ModelsNN2/Model_Checkpoint_Last.pt\"\n",
        "# load_path = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30/ModelsNN2/Model_Checkpoint_Last.pt\"\n",
        "\n",
        "# batch_size = 24\n",
        "\n",
        "# test = DataLoader(testdatasetNN2, batch_size=batch_size, shuffle=False, num_workers =1, pin_memory = True)\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# net = CollisionNetwork2().to(device)\n",
        "# net.load_state_dict(torch.load(load_path))\n",
        "# net.eval()\n",
        "\n",
        "# test_accuracy = torchmetrics.Accuracy() \n",
        "# test_recall = torchmetrics.Recall()\n",
        "# test_precision =  torchmetrics.Precision()\n",
        "# test_confusion = torchmetrics.ConfusionMatrix(num_classes=2)\n",
        "# Nsamples_ = 0\n",
        "# Tsamples_ = 0\n",
        "# for sample, target in test:\n",
        "#     sample, target = next(iter(test))\n",
        "#     target = target.squeeze()\n",
        "#     target = target.double()\n",
        "#     sample = sample.to(device)\n",
        "#     target = target.to(device)\n",
        "\n",
        "#     out = net(sample).squeeze()\n",
        "\n",
        "#     out_rounded = torch.round(out)\n",
        "#     target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "#     Tsamples = torch.sum(target)\n",
        "#     Nsamples = target.size(0) - Tsamples\n",
        "\n",
        "#     Tsamples_ += Tsamples\n",
        "#     Nsamples_ += Nsamples\n",
        "\n",
        "#     acc = test_accuracy(out_rounded, target_tensor)\n",
        "#     acc = acc.item()\n",
        "\n",
        "#     recall = test_recall(out_rounded, target_tensor)\n",
        "#     recall = recall.item()\n",
        "\n",
        "#     precision = test_precision(out_rounded, target_tensor)\n",
        "#     precision = precision.item()\n",
        "\n",
        "#     confusion = test_confusion(out_rounded, target_tensor)\n",
        "\n",
        "# total_test_accuracy = test_accuracy.compute()\n",
        "# print(f\"Accuracy: {total_test_accuracy}\")\n",
        "# test_accuracy.reset()\n",
        "# total_test_recall= test_recall.compute()\n",
        "# print(f\"Recall: {total_test_recall}\")\n",
        "# test_recall.reset()    \n",
        "# total_test_precision = test_precision.compute()\n",
        "# print(f\"Precision: {total_test_precision}\")\n",
        "# test_precision.reset()\n",
        "# total_test_confusion = test_confusion.compute()\n",
        "# print(f\"Confusion: {total_test_confusion}\")\n",
        "# test_confusion.reset()\n",
        "# print(Tsamples_)\n",
        "# print(Nsamples_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyPRwwxzK6ZH"
      },
      "source": [
        "\n",
        "# Third network: intentional v.s. unintentional classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghgXEIgaLBUn"
      },
      "outputs": [],
      "source": [
        "class CollisionNetwork3(nn.Module):\n",
        "\n",
        "\tdef __init__(self, no_layers=11, kernel = 3, device=None):\n",
        "\t\tsuper(CollisionNetwork3, self).__init__()\n",
        "\t\tself.no_layers = no_layers\n",
        "\t\tself.kernel = kernel\n",
        "\t\tself.layers = {}\n",
        "\t\tself.device = device\n",
        "\n",
        "\t\tself.Conv1d_1 = nn.Conv1d(1, 64, kernel, stride=1, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\tself.BatchNorm1d_1 = nn.BatchNorm1d(64, dtype=torch.double)\n",
        "\t\tself.ReLU_1= nn.ReLU(True)\n",
        "\n",
        "\t\tself.Conv1d_2 = nn.Conv1d(64, 128, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\tself.BatchNorm1d_2 = nn.BatchNorm1d(128, dtype=torch.double)\n",
        "\t\tself.ReLU_2= nn.ReLU(True)        \n",
        "\n",
        "\t\t# self.Conv1d_3 = nn.Conv1d(32, 32, kernel, stride=1, dilation=2, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_3 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_3= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_4 = nn.Conv1d(32, 32, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_4 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_4= nn.ReLU(True)    \n",
        "\t\n",
        "\t\t# self.Conv1d_5 = nn.Conv1d(32, 32, kernel, stride=1, dilation=4, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_5 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_5= nn.ReLU(True)        \n",
        "\n",
        "\t\t# self.Conv1d_6 = nn.Conv1d(32, 32, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_6 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_6= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_7 = nn.Conv1d(32, 32, kernel, stride=1, dilation=8, padding='valid', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_7 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_7= nn.ReLU(True)    \n",
        "\n",
        "\t\t# self.Conv1d_8 = nn.Conv1d(32, 32, kernel, stride=1, padding='same', bias=True, dtype=torch.double)\n",
        "\t\t# self.BatchNorm1d_8 = nn.BatchNorm1d(32, dtype=torch.double)\n",
        "\t\t# self.ReLU_8= nn.ReLU(True) \n",
        "\n",
        "\t\tself.Flatten = nn.Flatten()\n",
        "\t\n",
        "\t\tself.out = nn.Linear(8704,1, dtype=torch.double) \n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.Conv1d_1(x)\n",
        "\t\tx = self.BatchNorm1d_1(x)\n",
        "\t\tx = self.ReLU_1(x)\n",
        "\n",
        "\t\tx = self.Conv1d_2(x)\n",
        "\t\tx = self.BatchNorm1d_2(x)\n",
        "\t\tx = self.ReLU_2(x)\n",
        "\n",
        "\t\t# x = self.Conv1d_3(x)\n",
        "\t\t# x = self.BatchNorm1d_3(x)\n",
        "\t\t# x = self.ReLU_3(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_4(x)\n",
        "\t\t# x = self.BatchNorm1d_4(x)\n",
        "\t\t# x = self.ReLU_4(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_5(x)\n",
        "\t\t# x = self.BatchNorm1d_5(x)\n",
        "\t\t# x = self.ReLU_5(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_6(x)\n",
        "\t\t# x = self.BatchNorm1d_6(x)\n",
        "\t\t# x = self.ReLU_6(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_7(x)\n",
        "\t\t# x = self.BatchNorm1d_7(x)\n",
        "\t\t# x = self.ReLU_7(x)\n",
        "\t\t\n",
        "\t\t# x = self.Conv1d_8(x)\n",
        "\t\t# x = self.BatchNorm1d_8(x)\n",
        "\t\t# x = self.ReLU_8(x)\n",
        "\t\n",
        "\t\tx = self.Flatten(x)\n",
        "  \n",
        "\t\treturn self.out(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNkT6s5HLBYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "7a6cb2d9-6484-4f2d-dba6-a1f7c492f5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.797550618648529\n",
            "Accuracy: 0.8295426368713379\n",
            "Accuracy: 0.8505373597145081\n",
            "Accuracy: 0.857035756111145\n",
            "Accuracy: 0.8702824115753174\n",
            "Accuracy: 0.8700324892997742\n",
            "Accuracy: 0.8452886939048767\n",
            "Accuracy: 0.8625343441963196\n",
            "Accuracy: 0.8775306344032288\n",
            "Accuracy: 0.8607848286628723\n",
            "Accuracy: 0.8860284686088562\n",
            "Accuracy: 0.8932766914367676\n",
            "Accuracy: 0.8885278701782227\n",
            "Accuracy: 0.8912771940231323\n",
            "Accuracy: 0.8860284686088562\n",
            "Accuracy: 0.8865283727645874\n",
            "Accuracy: 0.9047738313674927\n",
            "Accuracy: 0.9047738313674927\n",
            "Accuracy: 0.8992751836776733\n",
            "Accuracy: 0.9022744297981262\n",
            "Accuracy: 0.9155211448669434\n",
            "Accuracy: 0.9152711629867554\n",
            "Accuracy: 0.9132716655731201\n",
            "Accuracy: 0.9022744297981262\n",
            "Accuracy: 0.9175206422805786\n",
            "Accuracy: 0.9240189790725708\n",
            "Accuracy: 0.9232692122459412\n",
            "Accuracy: 0.9152711629867554\n",
            "Accuracy: 0.930767297744751\n",
            "Accuracy: 0.9320169687271118\n",
            "Training Finished! Time Taken:  279.75229477882385\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "# save_path = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30/ModelsNN3\"\n",
        "save_path = save_path3\n",
        "\n",
        "train = DataLoader(traindataset3, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "test = DataLoader(testdataset3, batch_size=batch_size, shuffle=True, num_workers =1, pin_memory = True)\n",
        "\n",
        "#Defining the model and training it on loss function\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = CollisionNetwork3().to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(net.parameters())\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "criterion = nn.BCEWithLogitsLoss() \t\t\t#remove weight as dataset is balanced for soft int / unint\n",
        "\n",
        "\n",
        "loss_overall = []\n",
        "acc_overall = [None]*epochs\n",
        "recall_overall = [None]*epochs\n",
        "precision_overall = [None]*epochs\n",
        "acc_overall_test = [None]*epochs\n",
        "acc_overall_train = [None]*epochs\n",
        "time_start = time.time()\n",
        "print('Training Started')\n",
        "\n",
        "train_accuracy = torchmetrics.Accuracy() \t\t\t#in order to check if model learns properly\n",
        "# train_recall = torchmetrics.Recall()\n",
        "# train_precision =  torchmetrics.Precision()\n",
        "\n",
        "plt.figure()\n",
        "for i in range(epochs):\n",
        "\n",
        "  net.train(True)\n",
        "  step = 0\n",
        "  loss_= 0\n",
        "  for images, target in train:\n",
        "\n",
        "    # images, target = next(iter(train))\n",
        "    target = target.squeeze()\n",
        "    target = target.double()\n",
        "    images = images.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = net(images)\n",
        "    output = output.squeeze()\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    out_rounded = torch.round(output)\n",
        "    target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "    acc = train_accuracy(out_rounded, target_tensor)\n",
        "    acc_overall_test[i] = acc.item()\n",
        "\n",
        "    # recall = train_recall(out_rounded, target_tensor)\n",
        "    # recall_overall[i] = recall.item()\n",
        "\n",
        "    # precision = train_precision(out_rounded, target_tensor)\n",
        "    # precision_overall[i] = precision.item()\n",
        "\n",
        "    loss_+=loss\n",
        "    step+=1\n",
        "\n",
        "    # if(step%100 == 0):\n",
        "    #   print('Epoch:'+str(i)+'\\t'+ str(step) +'\\t Iterations Complete \\t'+'loss: ', loss.item()/1000.0)\n",
        "    #   loss_overall.append(loss_/1000.0)\n",
        "    #   loss_=0\n",
        "\n",
        "  total_train_accuracy = train_accuracy.compute()\n",
        "  print(f\"Accuracy: {total_train_accuracy}\")\n",
        "  train_accuracy.reset()\n",
        "  # total_train_recall= train_recall.compute()\n",
        "  # print(f\"Recall: {total_train_recall}\")\n",
        "  # train_recall.reset()    \n",
        "  # total_train_precision = train_precision.compute()\n",
        "  # print(f\"Precision: {total_train_precision}\")\n",
        "  # train_precision.reset()\n",
        "\n",
        "  #Saving the model\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "  if(i==epochs-1):\n",
        "    torch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+'Last'+'.pt')\n",
        "  else:\n",
        "    torch.save(net.state_dict(), save_path+'/Model_Checkpoint_'+str(i)+'.pt')\n",
        "\n",
        "  # net.eval()\n",
        "\n",
        "  # test_accuracy = torchmetrics.Accuracy() \n",
        "  # test_confusion = torchmetrics.ConfusionMatrix(num_classes=2)\n",
        "  # for sample, target in test:\n",
        "  #     target = target.squeeze()\n",
        "  #     target = target.double()\n",
        "  #     sample = sample.to(device)\n",
        "  #     target = target.to(device)\n",
        "\n",
        "  #     out = net(sample).squeeze()\n",
        "\n",
        "  #     out_rounded = torch.round(out)\n",
        "  #     target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "  #     acc = test_accuracy(out_rounded, target_tensor)\n",
        "  #     acc_overall_test[i] = acc.item()\n",
        "\n",
        "  #     confusion = test_confusion(out_rounded, target_tensor)\n",
        "\n",
        "  # total_test_accuracy = test_accuracy.compute()\n",
        "  # print(f\"Accuracy: {total_test_accuracy}\")\n",
        "  # test_accuracy.reset()\n",
        "  # total_test_confusion = test_confusion.compute()\n",
        "  # print(f\"Confusion: {total_test_confusion}\")\n",
        "  # test_confusion.reset()\n",
        "\n",
        "print('Training Finished! Time Taken: ', time.time()-time_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOApoL2NLBfh"
      },
      "outputs": [],
      "source": [
        "# load_path = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30/ModelsNN3/Model_Checkpoint_Last.pt\"\n",
        "\n",
        "# batch_size = 24\n",
        "\n",
        "# test = DataLoader(testdatasetNN3, batch_size=batch_size, shuffle=False, num_workers =1, pin_memory = True)\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# net = CollisionNetwork3().to(device)\n",
        "# net.load_state_dict(torch.load(load_path))\n",
        "# net.eval()\n",
        "\n",
        "# test_accuracy = torchmetrics.Accuracy() \n",
        "# test_recall = torchmetrics.Recall()\n",
        "# test_precision =  torchmetrics.Precision()\n",
        "# test_confusion = torchmetrics.ConfusionMatrix(num_classes=2)\n",
        "# Nsamples_ = 0\n",
        "# Tsamples_ = 0\n",
        "# for sample, target in test:\n",
        "#     sample, target = next(iter(test))\n",
        "#     target = target.squeeze()\n",
        "#     target = target.double()\n",
        "#     sample = sample.to(device)\n",
        "#     target = target.to(device)\n",
        "\n",
        "#     out = net(sample).squeeze()\n",
        "\n",
        "#     out_rounded = torch.round(out)\n",
        "#     target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "\n",
        "#     Tsamples = torch.sum(target)\n",
        "#     Nsamples = target.size(0) - Tsamples\n",
        "\n",
        "#     Tsamples_ += Tsamples\n",
        "#     Nsamples_ += Nsamples\n",
        "\n",
        "#     # print(out_rounded)\n",
        "#     # print(target_tensor)\n",
        "\n",
        "#     acc = test_accuracy(out_rounded, target_tensor)\n",
        "#     acc = acc.item()\n",
        "\n",
        "#     recall = test_recall(out_rounded, target_tensor)\n",
        "#     recall = recall.item()\n",
        "\n",
        "#     precision = test_precision(out_rounded, target_tensor)\n",
        "#     precision = precision.item()\n",
        "\n",
        "#     confusion = test_confusion(out_rounded, target_tensor)\n",
        "\n",
        "# total_test_accuracy = test_accuracy.compute()\n",
        "# print(f\"Accuracy: {total_test_accuracy}\")\n",
        "# test_accuracy.reset()\n",
        "# total_test_recall= test_recall.compute()\n",
        "# print(f\"Recall: {total_test_recall}\")\n",
        "# test_recall.reset()    \n",
        "# total_test_precision = test_precision.compute()\n",
        "# print(f\"Precision: {total_test_precision}\")\n",
        "# test_precision.reset()\n",
        "# total_test_confusion = test_confusion.compute()\n",
        "# print(f\"Confusion: {total_test_confusion}\")\n",
        "# test_confusion.reset()\n",
        "# print(Tsamples_)\n",
        "# print(Nsamples_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSJGWvxIbj-j"
      },
      "source": [
        "How will total pipeline look if only ramp samples are taken for classification of intensity and intensional? Wont work for period after collisionramp, as only trained on.\n",
        "\n",
        "for window\n",
        "do collision detection, if no collision return 0, if collision do classification, return 1, 2 or 3. \n",
        "If previous window was collision, return same number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl9xBCIJjObY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2678af-7afb-4782-ff0f-b5f36bbbfb43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion: tensor([[184,   2,   4,   4],\n",
            "        [  9,  14,   0,  13],\n",
            "        [  1,   0,  46,   0],\n",
            "        [  1,   1,   0,  27]])\n",
            "Accuracy: 0.8856209150326797\n"
          ]
        }
      ],
      "source": [
        "# # #only for cross-accuracy, otherwise comment out:\n",
        "# save_path1 = \"/content/drive/MyDrive/Colab Notebooks/Models_ds7_2layer_ch128_ch256_W30_avg2/ModelsNN1\"\n",
        "# save_path2 = \"/content/drive/MyDrive/Colab Notebooks/Models_ds7_2layer_ch128_ch256_W30_avg2/ModelsNN2\"\n",
        "# save_path3 = \"/content/drive/MyDrive/Colab Notebooks/Models_ds7_2layer_ch128_ch256_W30_avg2/ModelsNN3\"\n",
        "# evalset = CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/diff_ctrl_eval_W30/',0)\n",
        "evalset = CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/ds7_test_eval_avg2_W10/',0)\n",
        "\n",
        "# load_path_NN1 = save_path1+\"/Model_Checkpoint_Last.pt\"\n",
        "load_path_NN1 = save_path1+\"/Model_Checkpoint_23.pt\"\n",
        "load_path_NN2 = save_path2+\"/Model_Checkpoint_26.pt\"\n",
        "load_path_NN3 = save_path3+\"/Model_Checkpoint_25.pt\"\n",
        "\n",
        "batch_size = 1        #make 1 for boolean check of NN1 and NN2 to continue through the pipeline\n",
        "\n",
        "eval = DataLoader(evalset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_NN1 = CollisionNetwork().to(device)\n",
        "net_NN1.load_state_dict(torch.load(load_path_NN1))\n",
        "net_NN1.eval()\n",
        "net_NN2 = CollisionNetwork2().to(device)\n",
        "net_NN2.load_state_dict(torch.load(load_path_NN2))\n",
        "net_NN2.eval()\n",
        "net_NN3 = CollisionNetwork3().to(device)\n",
        "net_NN3.load_state_dict(torch.load(load_path_NN3))\n",
        "net_NN3.eval()\n",
        "\n",
        "mistakes = np.zeros(1)\n",
        "nmistakes = 0\n",
        "\n",
        "accuracy = 0\n",
        "count = 0\n",
        "final_confusion = torchmetrics.ConfusionMatrix(num_classes=4)\n",
        "for sample, target in eval:\n",
        "    sample = sample.to(device)\n",
        "    target = target.to(device)\n",
        "    target = target.squeeze()\n",
        "    target = target.double()\n",
        "\n",
        "    out = net_NN1(sample).squeeze()\n",
        "    out_rounded = torch.round(out)\n",
        "    target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "    # if target >= 1:           #so we get 100% accuracy NN1 and test 2 and 3 without the need of a new dataset\n",
        "    if out_rounded >= 1:                      #-- if collision is detected\n",
        "        out = net_NN2(sample).squeeze()\n",
        "        out_rounded = torch.round(out)\n",
        "        if out_rounded <= 0:                  # --if collision is hard\n",
        "          out_final = 1\n",
        "        else:\n",
        "          out = net_NN3(sample).squeeze()\n",
        "          out_rounded = torch.round(out)\n",
        "          if out_rounded <= 0:                # --if collision is intentional\n",
        "            out_final = 2\n",
        "          else:                               # --if collision is unintentional\n",
        "            out_final = 3\n",
        "    else:                                     # --if no collision is detected\n",
        "      out_final = 0\n",
        "\n",
        "    out_final = torch.tensor([out_final], dtype=torch.int8)\n",
        "    confusion = final_confusion(out_final, target_tensor)\n",
        "\n",
        "    # print(out_final.item(), int(target.item()))\n",
        "\n",
        "    count += 1\n",
        "    if (out_final == target_tensor.item()):\n",
        "      accuracy += 1\n",
        "      mistakes = np.append(mistakes,nmistakes)\n",
        "    else:\n",
        "      nmistakes +=1\n",
        "      mistakes = np.append(mistakes,nmistakes)\n",
        "      \n",
        "total_final_confusion= final_confusion.compute()\n",
        "print(f\"Confusion: {total_final_confusion}\")\n",
        "final_confusion.reset()\n",
        "\n",
        "final_accuracy = accuracy/count\n",
        "print(f\"Accuracy: {final_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeBfR0TUlDcZ"
      },
      "outputs": [],
      "source": [
        "# # W = 30\n",
        "\n",
        "# # save_path1 = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30_sameset_norm_avg/ModelsNN1\"\n",
        "# # save_path2 = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30_sameset_norm_avg/ModelsNN2\"\n",
        "# # save_path3 = \"/content/drive/MyDrive/Colab Notebooks/Models_separate_W30_sameset_norm_avg/ModelsNN3\"\n",
        "# # evalset = CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/new_separate_eval_norm_avg_W30/',0)\n",
        "\n",
        "# # load_path_NN1 = save_path1+\"/Model_Checkpoint_4.pt\"\n",
        "# # load_path_NN2 = save_path2+\"/Model_Checkpoint_Last.pt\"\n",
        "# # load_path_NN3 = save_path3+\"/Model_Checkpoint_Last.pt\"\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# net_NN1 = CollisionNetwork().to(device)\n",
        "# net_NN1.load_state_dict(torch.load(load_path_NN1))\n",
        "# net_NN1.eval()\n",
        "# net_NN2 = CollisionNetwork2().to(device)\n",
        "# net_NN2.load_state_dict(torch.load(load_path_NN2))\n",
        "# net_NN2.eval()\n",
        "# net_NN3 = CollisionNetwork3().to(device)\n",
        "# net_NN3.load_state_dict(torch.load(load_path_NN3))\n",
        "# net_NN3.eval()\n",
        "\n",
        "# eval = DataLoader(evalset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# time_total = 0\n",
        "# for sample, target in eval:\n",
        "#   get_time = sample.to(device)\n",
        "#   time_start1 = time.time()\n",
        "#   out1 = net_NN1(get_time).squeeze()\n",
        "#   out2 = net_NN2(get_time).squeeze()\n",
        "#   out3 = net_NN3(get_time).squeeze()\n",
        "#   time_end1 = time.time()\n",
        "  \n",
        "#   time_total += time_end1-time_start1\n",
        "\n",
        "\n",
        "\n",
        "# print(time_total/evalset.__len__())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUsY97Vim9LV"
      },
      "outputs": [],
      "source": [
        "# def count_parameters(model):\n",
        "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# # count_parameters(net_NN1)\n",
        "# count_parameters(net_NN1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENc_q2kB_RFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "f63f3bb0-8d02-470e-9154-453f7568bb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion: tensor([[176,   9,   5,   4],\n",
            "        [  9,  12,   0,  15],\n",
            "        [  1,   0,  46,   0],\n",
            "        [  1,   1,   4,  23]])\n",
            "Accuracy: 0.8398692810457516\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-57c2e4c3d845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mout_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_final\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_confusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_full_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_reduce_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# calculate batch state and compute batch value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m                             \u001b[0;34m\" device corresponds to the device of the input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                         ) from err\n\u001b[0;32m--> 405\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_on_cpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/confusion_matrix.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGround\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mconfmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_confusion_matrix_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfmat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mconfmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/confusion_matrix.py\u001b[0m in \u001b[0;36m_confusion_matrix_update\u001b[0;34m(preds, target, num_classes, threshold, multilabel)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mconfmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         \u001b[0mconfmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 4]' is invalid for input of size 19"
          ]
        }
      ],
      "source": [
        "# load_path_NN1 = save_path1+\"/Model_Checkpoint_Last.pt\"\n",
        "# load_path_NN2 = save_path2+\"/Model_Checkpoint_Last.pt\"\n",
        "# load_path_NN3 = save_path3+\"/Model_Checkpoint_Last.pt\"\n",
        "\n",
        "# batch_size = 1        #make 1 for boolean check of NN1 and NN2 to continue through the pipeline\n",
        "\n",
        "# eval = DataLoader(evalset, batch_size=batch_size, shuffle=False)\n",
        "# # eval2 = DataLoader(evaldataset2, batch_size=batch_size, shuffle=False)\n",
        "# # eval3 = DataLoader(evaldataset3, batch_size=batch_size, shuffle=False)\n",
        "# # eval_list = [eval1, eval2, eval3]\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# net_NN1 = CollisionNetwork().to(device)\n",
        "# net_NN1.load_state_dict(torch.load(load_path_NN1))\n",
        "# net_NN1.eval()\n",
        "# net_NN2 = CollisionNetwork2().to(device)\n",
        "# net_NN2.load_state_dict(torch.load(load_path_NN2))\n",
        "# net_NN2.eval()\n",
        "# net_NN3 = CollisionNetwork3().to(device)\n",
        "# net_NN3.load_state_dict(torch.load(load_path_NN3))\n",
        "# net_NN3.eval()\n",
        "\n",
        "# # preds = np.zeros(1)\n",
        "# # targets = np.zeros(1)\n",
        "# mistakes = np.zeros(1)\n",
        "# nmistakes = 0\n",
        "# eval_count = 0\n",
        "# for eval2 in eval:\n",
        "#   accuracy = 0\n",
        "#   count = 0\n",
        "#   final_confusion = torchmetrics.ConfusionMatrix(num_classes=4)\n",
        "#   for sample, target in eval:\n",
        "#       # sample, target = next(iter(eval))\n",
        "#       sample = sample.to(device)\n",
        "#       target = target.to(device)\n",
        "#       target = target.squeeze()\n",
        "#       target = target.double()\n",
        "\n",
        "#       if eval_count == 1:\n",
        "#         target = target*2\n",
        "#       if eval_count == 2:\n",
        "#         target = target*3\n",
        "\n",
        "#       out = net_NN1(sample).squeeze()\n",
        "#       out_rounded = torch.round(out)\n",
        "#       target_tensor = torch.tensor(target, dtype=torch.int8)\n",
        "#       if out_rounded >= 1:                      #-- if collision is detected\n",
        "#           out = net_NN2(sample).squeeze()\n",
        "#           out_rounded = torch.round(out)\n",
        "#           if out_rounded <= 0:                  # --if collision is hard\n",
        "#             out_final = 1\n",
        "#           else:\n",
        "#             out = net_NN3(sample).squeeze()\n",
        "#             out_rounded = torch.round(out)\n",
        "#             if out_rounded <= 0:                # --if collision is intentional\n",
        "#               out_final = 2\n",
        "#             else:                               # --if collision is unintentional\n",
        "#               out_final = 3\n",
        "#       else:                                     # --if no collision is detected\n",
        "#         out_final = 0\n",
        "\n",
        "#       #maybe write this as a 3xn array so each evalset is separate\n",
        "#       # preds = np.append(preds,out_final)\n",
        "#       # targets = np.append(targets,target)\n",
        "\n",
        "#       out_final = torch.tensor([out_final], dtype=torch.int8)\n",
        "#       confusion = final_confusion(out_final, target_tensor)\n",
        "\n",
        "#       count += 1\n",
        "#       if (out_final == target_tensor.item()):\n",
        "#         accuracy += 1\n",
        "#         mistakes = np.append(mistakes,nmistakes)\n",
        "#       else:\n",
        "#         nmistakes +=1\n",
        "#         mistakes = np.append(mistakes,nmistakes)\n",
        "        \n",
        "#   eval_count +=1\n",
        "\n",
        "#   total_final_confusion= final_confusion.compute()\n",
        "#   print(f\"Confusion: {total_final_confusion}\")\n",
        "#   final_confusion.reset()\n",
        "\n",
        "#   final_accuracy = accuracy/count\n",
        "#   print(f\"Accuracy: {final_accuracy}\")\n",
        "\n",
        "# # for item in preds:\n",
        "# #   item = int(item)\n",
        "# # for item in targets:\n",
        "# #   item = int(item)\n",
        "\n",
        "# # with open(\"/content/drive/MyDrive/Colab Notebooks/data/preds\", \"a\") as f:\n",
        "# #     np.savetxt(f, preds, fmt='%.1i')\n",
        "# # with open(\"/content/drive/MyDrive/Colab Notebooks/data/labels\", \"a\") as f:\n",
        "# #     np.savetxt(f, preds, fmt='%.1i')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn3hQirRxz6q"
      },
      "outputs": [],
      "source": [
        "# mistakes = mistakes[1:]\n",
        "# plt.plot(mistakes)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK6WETF1-LRp"
      },
      "outputs": [],
      "source": [
        "# eval_dataset =  CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/eval_set_W100_overlap/')\n",
        "# # eval_dataset =  CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/eval_set_W25/')\n",
        "\n",
        "# eval_dataset =  CollisionDataset('/content/drive/MyDrive/Colab Notebooks/data/eval_set_W30/')\n",
        "\n",
        "# W = 30\n",
        "\n",
        "# # list = [0,39,40,125,126, 395, 396]\n",
        "# list = [12,13,35,36,192,193,359,360]\n",
        "# for i in list:\n",
        "# # for i in range(151,155):\n",
        "#   source_sample, target_sample = eval_dataset.__getitem__(i)\n",
        "#   plt.figure()\n",
        "#   print(target_sample)\n",
        "#   tau = [[],[],[],[],[],[],[]]\n",
        "#   for i in range(7):\n",
        "#     for j in range(W):\n",
        "#       tau[i] = np.append(tau[i], source_sample[0][i+7*j])\n",
        "#     plt.plot(tau[i])\n",
        "#     plt.ylim([0,10])\n",
        "\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PkYhxhxoV8XKwLpq9302omLLgeMEP6k-",
      "authorship_tag": "ABX9TyNPETv9kSpW34NayWFxqSR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}